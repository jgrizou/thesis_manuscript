%!TEX root = ../thesis.tex

Why: So that audience can implement their own version of the algorithm. It means they should be convince it is a useful algorithm, known when to use it, be aware of the many assumptions and understand the underlying principle. 

There is only one simple idea to understand for the algorithm and one for the planning. I want to illustrate them using visual example. It should be the same all along the thesis. The T world seem the simplest one that shows the main element for feedback instructions. for the guidance it may be a bit more difficult.

Who: Specialist, but I do not want to dive into techincal aspect, the only thing that matter for me is that people reading understand the problem, our approach (no math just intuiion of how it works) so those guy that knows how to do machine learning and proof better than me can improve things easily. I will use the term we in most of the thesis cause the work is a common reflexion from people in and around the lab.

What: intro and related work cause it is necessary for the "who" guys. Brief motivation from the human experiment, then visual explanation of the problem, first a dummy symbolic one with maybe a proof followed by a 2D signal feedback one, then xp robot pick and place, then explanation of the planning problem + visual, then BCI example + prior information on the power, then limitation and example of what can be done to overcome them, then conclusion simple concise, no speculation on the future of robotic land.

When: End of June for a first advanced draft

Where: Latex, as short as possible, be concise

%%
\chapter{Introduction}
\minitoc

Why now: More and more intelligent system are coming into our daily life, making decision that can affect our everyday life.

Why the readers: Interacting with such system is therefore more and more difficult and often requires the user to adapt to the machine.

Why me: We need to develop system where interaction is made easy and adaptive wrt. each particular users. 

Why this chapter: present the further logical content of the document. Present the general problem of learning from unlabeled instruction in general terms, just the challenges that is interesting 

What: We first give the general scientific and societal context of our work from which arises some question, and follow the general ideas that has evolved in our respective. We are going down from the big picture to the tiny corner of interest for us. we then provide the logical content of the document t answer the so what and what now question.

So what: we need to study this corner into more details

What now: let look at what others have done to tune our understanding of the problem and broaden our view

This paper aims at solving the general problem of developing machines that can execute a task from human instructions and simultaneously learn the communicative signals.


\section{Intelligent system in our daily life}

\section{The challenge and benefit of fluid interaction}

%%
\chapter{Related work}
\minitoc

Context - Why now: show that I am real scientist that as read everything. lol

Need - Why the reader: so that it have enough pointer to situate the work in the learning from interaction word. Readers understand there is a gap that is interesting to ``study'' in more detail

Task - Why me: did the review no one cares

Object- Why this chapter: present several work starting from interactive learning, language games, unsupervised learning and human in the loop

Findings - What: we found that one main assumption is almost always made in interactive learning scenario, the frame is known, including the meaning of the signals. The interaction is always really structured with a context, some information about the relation of different things (arm to object, agent to goal location, assessment of actions...). [really put this forward in all sections]

Conclusions - So what: How can we remove a small part of this interaction, namely the assumption that the meaning of the signals should be known in advance.

Perspectives - What now: Maybe a first question to ask is how people would react to this.

\section{Interactive Learning}

\section{Language games}

\section{Unsupervised learning}

\subsection{Multimodal learning}

\section{Ad hoc team}

\section{The human in the loop}

%%
\chapter{How humans solve this problem}
\minitoc

ICDL paper with Anna-Lisa Vollmer and K.J. Rohlfing.

Context - Why now: We define a new challenge of interaction without pre-coordination for robot but does human can do this? A lot of work has been done in teaching devices from human instruction. However very few experiments considered the option to put a human in place of the robot with the quite restricted perception and/or capabilities, as robot have currently.

Need - Why the reader: We study the effect of how the H-H partners manage to work together.

Task - Why us: We performed an experiment where two user have asymmetric role and restricted communication

Object- Why this chapter: The following chapters presents in more detailed the related work concerning human experiments, the settings and interaction protocol.

Findings - What: We show that people manage to successfully interact and find out that they usually try to frame the interaction into universally known interaction patterns. We introduce the terms of interaction frame here. And find out that some frame are more recurrent and easily understood than the others. They solve the problem by hypothesizing on what the user would want to say in a given situation and match with the history of event for each button. Hypothesis generation and testing.

Conclusions - So what: Based on such observations, we could imagine a robot that is equipped with one or several interaction frame and try to find out what signal means what based on the history of interaction.

Perspectives - What now: We should now study if this approach could work in practice.

\section{Related work}

\subsection{Experimental semiotic}

\section{The Collaborative Construction Game}

\section{Experiments}

\section{Lessons Learned} % discussion

Introduce interaction frame here
What do we learn from this? 
How can it be used to build an algorithm?

%%
\chapter{Learning from unlabeled interaction frames}
\minitoc

Context - Why now: we identified a potential mechanism.

Need - Why the reader: we must now investigate if it can work.

Task - Why me: we developed a new algorithm that formalize the observed constraints depicted before

Object- Why this chapter:  we will start by presenting symbolic experiment where we can observe and maybe prove that the algorithm make sense. We then exemplify on non symbolic data. We then define the terms of the algorithm and the idea of the metric we measure, and the many assumption we do. We then test the algorithm on a pick and place scenario using a 6 dof robot and speech utterances as the modality of interaction.

Findings - What: it works well for feedback and guidance case in 100 or 200 iterations with different classifiers and it is robust to some mistake from the teacher.

Conclusions - So what: So we can envision interacting with system without pre coordination. 

Perspectives - What now: However the question of how the robot should act as been left assigned with random movement or greedy strategies. it has been shown on similar setup but when the signal to meaning is known that learning time can be improve by having an agent seek for more informative signals. Next section present how our robot can plan its action to do better.

\section{Problem formulation and assumptions}

\subsection{Interaction frame}

\subsection{Learning Algorithm}

\section{What we exploit}

\section{How do we exploit it}

\section{Method}

\section{Results}

\section{Discussion}

%%
\chapter{Planning action efficiently}
\minitoc

Context - Why now: we shown that we can solve the problem but did not considered the problem of planning

Need - Why the reader: the planning has been shown to be an important aspect of most online real world learning system, 

Task - Why me: we investigated the problem of uncertainty in our problem

Object- Why this chapter: We start by providing an intuition on what are the sources of uncertainty inherent to our problem. Describe a metric that is able to measure it and show on simulated experiment that this method is more efficient than several standard ones.

Findings - What: We identified two sources of uncertainty in for our problem and combined them into one efficient metrics that reduce to other method if the mapping between signal and meaning was known

Conclusions - So what: We can improve the learning efficiency of such a system that become aware of the information it misses or it miss model and can actively try to recover from this.

Perspectives - What now: how does it apply to a real word complex scenario. actually useful for some person that can't use button and where signal are never the same, where some universal classifier does no exist.

\section{Problem formulation and assumptions}

\section{What is different with our setup that should be exploited, visual example}

\section{How do we exploit it}

refer to the video I did

%%
\chapter{Application to brain computer interaction}
\minitoc

With I\~naki Iturrate and Luis Montesano.

Context - Why now: We have a working algorithm, in simulation or with pretty god data

Need - Why the reader: we want to test it on a realistic setup with signal which make sense to use in tis context, BCI seems a promising direction

Task - Why us: Together with I\~naki Iturrate and Luis Montesano we adapted the algorithm to work with EEG signal on a grid world setup.

Object- Why this chapter:  We present first the EEG paradigm and related work in the domain. Then show simulated experiment using prerecorded data, and finally show some run with some real users.

Findings - What: It works online, with naive subject, and without pre-calibration, but the performance are no the same than in simulation

Conclusions - So what: We can hope to release this algorithm in the real word and make it useful to use. EEG are among the hardest signal to classify, if we can do it with them, we sure can do it with other king of signals.

Perspectives - What now: That are only toy problem, discrete state, discrete action, where should we go next? What are the current limitation?

%%
\chapter{Limitations and Extensions}
\minitoc

Context - Why now: We have shown an algortihm that seems to work

Need - Why the reader: we need to know what are the hidden assumption that are really done and how to overcome them. And potential way to go into more complex problems

Task - Why me: I investigated this question and ran some proof of concept experiment that demonstrate my points.

Object - Why this chapter: We list a number of limitation (continuous state, finite set of task, pre-defined unique interaction frame, human is not affected by agent behavior). We then provide ideas to solve that problem and illustrate with some more or less toy example.

Findings - What: We found that there is some limitation and that some direction are shown to be working in simple scenarios.

Conclusions - So what: Let's go work on finding the limitation

Perspectives - What now: 

\section{Continuous state space}
the frontiers xp

\section{Finite set of Hypothesis}
a simple particle filter

\section{Pre-defined interaction frame}
first freeze the number of task and find the correct interaction frame from a set of interaction frame
second, have two set, one for the frame one for the task

\section{Human in the loop}
how does the agent behavior affect the algorithm assumption on human behavior

Assumption: The properties of the signals do not change wrt. the behavior of the agent

Users comply with the frame implemented. Same meaning, optimal strategies, timing...

discuss how the setup can be used in HRI, but also semiotic stuff...

\section{Word properties}
xp with a grid world versus a real maze with many wall and see that random becomes a joke

%%
\chapter{Conclusion}
\minitoc

Context - Why now: we have developed a complete solution

Need - Why the reader: we must wrap up the all shit 

Task - Why me: We have show that there is some problem that were not or very few people tackled it before and tried to identify the problem, how to solve, implemented it and shown that it works, also with BCI, and presented many limitation and some direction to overcome them

Object- Why this chapter: Same thing as above

Findings - What: we have a complete document that present a complete theory

Conclusions - So what: well you can try to use this shit and make real proof of it, maybe study it in different settings, and different signals and more symbolic stuff which are easier and you will say it is brand new, and publish more conference paper that will say again the same thing as we did in a different way showing that you changed the world.

Perspectives - What now: let's go further with having agent learning meanings

The transition from raw input to higher level meaning is however not much investigated in science. Here our agent or robot already have the ability to categorize state, make plans and select what is relevant from the environment.

The only example known today is the Siri interface from apple that learn to adapt to each particular user voice specificities.






