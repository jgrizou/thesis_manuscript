%!TEX root = ../thesis.tex

\begin{vcenterpage}
\noindent\rule[2pt]{\textwidth}{0.5pt}
\begin{center}
{\large\textbf{\thesistitle\\}}
\end{center}
{\large\textbf{Abstract:}} Intelligent systems are more and more integrated into human environement. We need to communicate with them in a way that we do not have to always comply to the use of a predefine interface that may be boring blabla. We study the particular problem of calibration. We first show that human are capable to solve this problem and derive from their behavior an algorithm that allow to interact with a machine without specifing in advance the specific signal required. We show that this performs better than a calibration procedure. We show that we can derive a planning strategy for such a system that takes into account the uncertainty on both the signal and the task space.

This work opens new perspective in the way we could interact with intelligent machine in a seamless and transparent manner. blabla\\

We present an algorithm allowing a user to teach a robot a new task using unknown instruction signals. For this work, we consider different scenarios where a human teacher uses initially unclassified speech words, whose associated meaning can be a feedback (good/bad) or a guidance (go left, right, up, ...). We present computational results, within an inverse reinforcement learning framework, showing that: a) it is possible to learn the meaning of unknown and noisy teaching signals, as well as a new task at the same time, b) it is possible to reuse the acquired knowledge about teaching signals for learning new tasks and c) even in the case where the robot initially knows some of the teaching signals' meanings, the use of extra unknown teaching signals improves learning efficiency. We further introduce an efficient planning strategy that exploits the task and instruction uncertainty to allow more efficient learning sessions.

In interaction, humans align and effortlessly create common ground in communication, allowing efficient collaboration in widely diverse contexts.
Robots are still far away from being able to adapt in such a flexible manner with non-expert humans to complete collaborative tasks. Challenges include the capability to understand unknown feedback or guidance signals, to make sense of what they refer to depending on their timing and context, and to agree on how to organize the interaction into roles and turns. 
As a first step in approaching this issue, we investigate here the processes used by humans to negotiate a protocol of interaction when they do not already share one.
We introduce a new experimental setup, where two humans have to collaborate to solve a task. The channels of communication they can use are constrained and force them to invent and agree on a shared interaction protocol in order to solve the task. These constraints allow us to analyze how a communication protocol is progressively established through the interplay and history of individual actions. We report preliminary results obtained from a pilot study, and discuss how the understanding of strategies used by humans could be useful to achieve more flexible HRI.

Interactive learning deals with the problem of learning and solving tasks using human instructions. It is common in human-robot interaction, tutoring systems and in human-computer interfaces such as brain-computer ones. In most cases, learning these tasks is possible because the signals are predefined or an ad-hoc calibration procedure allows to map signals to specific meanings. In this paper, we address the problem of simultaneously solving a task under human feedback and learning the meaning of the feedback signals. 
This has important practical application since the user can start controlling a device from scratch, without the need of an expert to define the meaning of signals or carrying out a calibration phase. The paper proposes an algorithm that simultaneously assign meanings to signals while solving a sequential task under the assumption that both, human and machine, share the same a priori on the possible instruction meanings and the possible tasks. Furthermore, we show using synthetic and real EEG data from a brain-computer interface that taking into account the uncertainty of the task and the signal is necessary for the machine to actively plan how to solve the task efficiently. 

{\large\textbf{Keywords:}}
Keyword 1, Keyword2.\\

\noindent\rule[2pt]{\textwidth}{0.5pt}
\end{vcenterpage}