%!TEX root = ../../thesis.tex
\define{\chapterpath}{\allchapterspath/introduction}
\define{\imgpath}{\chapterpath/img}

\chapter{Introduction}
\label{chapter:introduction}
\minitoc


In the past decades, robotics and autonomous systems have seen tremendous improvement in their motor, perceptual, and computational capabilities. As a good example, we have been able to send and operate rovers for several years on the planet Mars (Spirit, Opportunity, Curiosity), which indicates the technologies are well mastered. However, getting such robots to do what we want them to do remains a skill of few, and bringing robotics system capable of social interaction in our daily life has been identified as the next milestone for the robotic community.

As for bringing computers in all our homes required easy and intuitive ways for people to make use of them, bringing robots in our daily life requires easy and intuitive ways for people to make robots do useful things for them. Currently, implementing advance behaviors in a robot, such as folding a shirt, requires similar skills than a computer scientist needed 50 years ago to build a spreadsheet application using punch cards, i.e. a lot of expertise, patience and trials and errors development. Due to the diversity of skills a robot should be able to execute in our daily environment, including interacting with humans and objects, traditional programming methods hinder the deployment of robotic system at homes and workspaces.

Instead, researchers are trying to endow robotic systems with the ability to learn from social interaction what tasks to execute and how they should be executed. Several methods have been considered to allow non-technical users to ``program'' robots, such as \emph{learning by demonstration} where the human demonstrate the skills to the robot, \emph{learning from instruction} where the human explains the sequence of actions to performs in order to fulfill the task, or \emph{learning from feedback} where the human assesses the actions of the robot with respect to the aimed behavior. Advances in these areas should allow the emergence of robot companions, living inside our homes providing assistance to the daily tasks, care, and entertainment. 

Endowing a robot with the ability to learn form interaction with a human partners requires to solve several challenges: the technical challenge of motor, perceptual and cognitive skills acquisition and generalization, the practical challenge of interacting in a social way with human being of different background. Especially, the robot must be able to understand the communicative signals from the human and communicate its own intention and ``state of mind'' back to the human. Additionally, as robots are embodied agent, the challenge of interaction and social acceptance of robot among people is an additional obstacle. A robot that is not accepted by people will not be used, and a robot that cannot be understood by people or a non-intuitive interface is likely to impact the performances of the learning systems developed.

Currently most of the challenges are considered in isolation. For example, when a robot learns a task from human instruction, it is assumed the robot receives instruction in a symbolic representation, e.g. if the human uses speech to communicate his instructions, the robot is assumed to be able convert speech into text and to extract relevant keywords in the sentence. Similarly, when a robot learns how to recognize speech utterances, which is how to convert raw speech into a meaningful representation, the robot is usually fed with the association between speech utterances and their meanings.

In this thesis, we try to consider the latter challenges simultaneously which is learning a new task from raw human instructions signals whose associated meanings are initially unknown. Our approach consists of generating interpretation of the signals with respect to different hypothetic task and selects the one that best explain the history of interaction.

% In the following sections, we detail more the challenges of learning from interaction, explicit the usual assumption made, and describe the contribution of the thesis.

\section{Learning from Interaction}


\section{Usual Assumptions}


\section{Thesis Contributions}


\cite{grizou2014interactive}
\cite{grizou2014calibration}
\cite{grizou2013robot}


\cite{grizou2014robot}
\cite{grizou2013zero}
\cite{grizou2013interactive}


\section{Thesis Outline}

The first aim of this manuscript is to explain the problem of learning from unlabeled interaction frames and to provide an intuition on what properties can be exploited to solve this problem. We introduce the most important aspects of the work by simple visualization of the problem and of the specific properties we exploit. Our objective is therefore to endow the interested readers with sufficient understanding of the problem to implement their own version of the algorithm with the tools they are more familiar with.

In chapter~\ref{chapter:relatedwork}, we present an overview of the related work which span from language acquisition to brain computer interfaces.

In chapter~\ref{chapter:humanexperiment}, we introduce a new experimental setup to study the co-construction of interaction protocols in asymmetric collaborative tasks with humans. By presenting preliminary results based on this setup, we derive interesting lessons for our problem. This work on human experiment is a joint collaboration with Anna-Lisa Vollmer and Katharina J. Rohlfing. 

In chapter~\ref{chapter:lfui}, we introduce in more specific terms the problem and provide a visual intuition on what properties we will exploit. We continue by formalizing the problem in a probabilistic framework, describe how particular brick of the problem are implemented and present results from a robotic pick and place scenario.

In chapter~\ref{chapter:planning}, we introduce the planning specificities related to our problem and provide a visual intuition on what properties we should track. We continue by defining the uncertainty measure used in the planning process and demonstrate on a 2D grid world problem the efficiency of the method with respect to other planning strategies.

In chapter~\ref{chapter:bci}, we present an application of the algorithm to a BCI scenario where a subject control an agent on a grid. We report online experiment showing that our algorithm allows untrained subjects to start controlling a device without any calibration procedure and by mentally assessing the device's actions. This work on BCI is a joint collaboration with I{\~n}aki Iturrate and Luis Montesano.

In chapter~\ref{chapter:limitations}, we discuss the limitation of the work and exemplify, using simulated experiments, direction which could be pursue to overcome them.