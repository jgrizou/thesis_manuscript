%!TEX root = ../../thesis.tex
\renewcommand{\chapterpath}{\allchapterspath/conclusion}
\renewcommand{\imgpath}{\chapterpath/img}

\chapter{Conclusion}
\label{chapter:conclusion}
\minitoc


Context - Why now: we have developed a complete solution

Need - Why the reader: we must wrap up the all shit 

Task - Why me: We have show that there is some problem that were not or very few people tackled it before and tried to identify the problem, how to solve, implemented it and shown that it works, also with BCI, and presented many limitation and some direction to overcome them

Object- Why this chapter: Same thing as above

Findings - What: we have a complete document that present a complete theory

Conclusions - So what: well you can try to use this shit and make real proof of it, maybe study it in different settings, and different signals and more symbolic stuff which are easier and you will say it is brand new, and publish more conference paper that will say again the same thing as we did in a different way showing that you changed the world.

Perspectives - What now: let's go further with having agent learning meanings

The transition from raw input to higher level meaning is however not much investigated in science. Here our agent or robot already have the ability to categorize state, make plans and select what is relevant from the environment.

The only example known today is the Siri interface from apple that learn to adapt to each particular user voice specificities.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In this paper we have shown that, given a limited number of possible tasks, it is possible to solve sequential tasks using human feedback without defining a map between feedback signals and their meaning beforehand. The proposed algorithm optimizes a pseudo-likelihood function and performs active planing according to the the uncertainty in the task and meaning spaces. Indeed, taking into account this uncertainty is crucial to solve the task efficiently and to recover the actual meanings. This combination allows: 
\begin{inparaenum}[a)]
\item a human to start interacting with a system without calibration;
\item to automatically adapt calibration time to the user needs which can even outperform fixed calibration procedures; 
\item to adapt to the uncertainty of the information source from scratch.
\end{inparaenum}
We showed the applicability of the approach to brain-machine interfaces based on error potentials which could work out of the box without calibration, a long-desired property of this type of systems.  